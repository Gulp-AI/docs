---
title: "Basic Streaming"
description: "Getting started with basic streaming in Gulp"
---

# Basic Streaming Example

This example demonstrates a basic streaming application using Gulp.

## Simple Event Processing

```yaml
name: "Simple Event Processing"
version: "1.0.0"

watermarkConfig:
  timeCharacteristic: PROCESSING_TIME
  maxOutOfOrderness: 0

source:
  type: "kafka"
  config:
    bootstrapServers: "${KAFKA_BOOTSTRAP_SERVERS}"
    topic: "events"
    groupId: "event-processor"
    startingOffsets: "latest"
    
transformations:
  - name: "Parse JSON"
    type: "deserialize"
    format: "json"
    schema:
      type: "object"
      properties:
        event_type:
          type: "string"
        user_id:
          type: "string"
        timestamp:
          type: "long"
        data:
          type: "object"
    
  - name: "Filter Valid Events"
    type: "filter"
    filterRule:
      field: "event_type"
      operator: "is_not_null"
    
  - name: "Enrich Events"
    type: "map"
    fields:
      - name: "processed_timestamp"
        value: "CURRENT_TIMESTAMP"
        type: "long"
      - name: "environment"
        value: "${ENV}"
        type: "string"
        
sink:
  type: "kafka"
  config:
    bootstrapServers: "${KAFKA_BOOTSTRAP_SERVERS}"
    topic: "processed-events"
    deliveryGuarantee: "exactly_once"
    producerConfig:
      compression.type: "snappy"
      batch.size: 65536
```

## Configuration Explanation

### Source Configuration
- Reads events from a Kafka topic
- Uses environment variables for connection details
- Configures consumer group for scalability

### Transformations
1. **Parse JSON**: Deserializes incoming messages with schema validation
2. **Filter**: Removes invalid events
3. **Enrichment**: Adds processing metadata

### Sink Configuration
- Writes to output Kafka topic
- Ensures exactly-once delivery
- Optimized producer settings for throughput 