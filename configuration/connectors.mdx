---
title: "Connectors"
description: "Comprehensive guide to source and sink connectors in Gulp"
---

# Connectors

Gulp provides a rich set of connectors for integrating with various data sources and sinks. This guide covers all available connectors and their configurations.

## Source Connectors

### 1. Kafka Source

Connect to Apache Kafka topics:

```yaml
sources:
  - id: "kafkaSource"
    type: "kafka"
    name: "Kafka Input Stream"
    config:
      bootstrapServers: "kafka1:9092,kafka2:9092"
      topic: "input-topic"
      groupId: "gulp-consumer-group"
      startingOffsets: "earliest"  # earliest, latest, or timestamp
      consumerProperties:
        "security.protocol": "SASL_SSL"
        "sasl.mechanism": "PLAIN"
      deserializationSchema:
        type: "json"  # json, avro, or custom
    schema:
      type: "object"
      properties:
        userId:
          type: "string"
        timestamp:
          type: "number"
        value:
          type: "double"
```

### 2. Mock Source

Useful for testing and development:

```yaml
sources:
  - id: "mockSource"
    type: "mock"
    name: "Mock Data Generator"
    config:
      emitInterval: 1000  # milliseconds
      generatorConfig:
        type: "random"  # random, sequence, or custom
        fields:
          - name: "userId"
            type: "string"
            pattern: "user-[0-9]{5}"
          - name: "value"
            type: "double"
            min: 0.0
            max: 100.0
    schema:
      type: "object"
      properties:
        userId:
          type: "string"
        value:
          type: "double"
```

## Sink Connectors

### 1. Kafka Sink

Write to Apache Kafka topics:

```yaml
sinks:
  - id: "kafkaSink"
    type: "kafka"
    name: "Kafka Output Stream"
    input: "transformedStream"
    config:
      bootstrapServers: "kafka1:9092,kafka2:9092"
      topic: "output-topic"
      producerProperties:
        compression.type: "snappy"
        batch.size: 16384
        linger.ms: 5
      serializationSchema:
        type: "json"
        prettyPrint: false
      deliveryGuarantee: "exactly_once"  # exactly_once, at_least_once
```

### 2. Print Sink

Useful for debugging and development:

```yaml
sinks:
  - id: "printSink"
    type: "print"
    name: "Console Output"
    input: "processedStream"
    config:
      prefix: "[GULP] "
      includeTimestamp: true
      outputMode: "append"  # append, complete, update
```

## Common Configuration

### 1. Schema Definition

All sources require a schema definition:

```yaml
schema:
  type: "object"
  properties:
    field1:
      type: "string"
      description: "Field description"
    field2:
      type: "integer"
      minimum: 0
      maximum: 100
    field3:
      type: "object"
      properties:
        nested1:
          type: "string"
        nested2:
          type: "number"
  required: ["field1", "field2"]
```

### 2. Error Handling

Configure error handling for connectors:

```yaml
errorHandling:
  retryStrategy:
    maxAttempts: 3
    backoffMultiplier: 2
    initialBackoff: "1s"
  deadLetterQueue:
    enabled: true
    topic: "error-records"
  errorOutputs:
    - name: "validationErrors"
      condition: "error.type == 'validation'"
    - name: "connectionErrors"
      condition: "error.type == 'connection'"
```

## Performance Tuning

### 1. Kafka Source Tuning

```yaml
sources:
  - id: "optimizedKafkaSource"
    type: "kafka"
    config:
      fetchMinBytes: 1048576  # 1MB
      fetchMaxWaitMs: 500
      maxPartitionFetchBytes: 5242880  # 5MB
      receiveBufferBytes: 1048576  # 1MB
      maxPollRecords: 500
      consumerProperties:
        isolation.level: "read_committed"
```

### 2. Kafka Sink Tuning

```yaml
sinks:
  - id: "optimizedKafkaSink"
    type: "kafka"
    config:
      batchSize: 16384
      lingerMs: 5
      compressionType: "snappy"
      maxInFlightRequests: 5
      retries: 3
      enableIdempotence: true
      maxRequestSize: 1048576  # 1MB
```

## Monitoring

### 1. Metrics Configuration

```yaml
monitoring:
  metrics:
    - name: "recordsProcessed"
      type: "counter"
      labels: ["connector", "type"]
    - name: "processingLatency"
      type: "histogram"
      labels: ["connector"]
    - name: "bytesProcessed"
      type: "meter"
      labels: ["connector"]
```

### 2. Health Checks

```yaml
healthChecks:
  - name: "kafkaConnectivity"
    type: "connection"
    target: "kafka"
    interval: "30s"
    timeout: "5s"
  - name: "recordProcessing"
    type: "throughput"
    minimum: 100  # records/second
    window: "5m"
```

## Testing

### 1. Mock Source Configuration

```yaml
testConfig:
  mockSources:
    - id: "testSource"
      schema:
        type: "object"
        properties:
          message:
            type: "string"
          count:
            type: "integer"
          price:
            type: "number"
          active:
            type: "boolean"
      data:
        - message: "test1"
          count: 1
          price: 10.5
          active: true
        - message: "test2"
          count: 2
          price: 20.5
          active: false
```

### 2. Validation Tests

```yaml
testConfig:
  validationTests:
    - name: "KafkaConnectorTest"
      source:
        type: "kafka"
        config:
          bootstrapServers: "localhost:9092"
          topic: "test-topic"
      expectations:
        - recordCount: 100
        - processingTime: "5s"
        - errorRate: 0.0
```

## Security

### 1. Authentication

```yaml
security:
  authentication:
    type: "sasl"
    mechanism: "PLAIN"
    username: "${KAFKA_USERNAME}"
    password: "${KAFKA_PASSWORD}"
    
  encryption:
    enabled: true
    protocol: "TLS"
    truststore:
      path: "/path/to/truststore.jks"
      password: "${TRUSTSTORE_PASSWORD}"
    keystore:
      path: "/path/to/keystore.jks"
      password: "${KEYSTORE_PASSWORD}"
```

### 2. Authorization

```yaml
security:
  authorization:
    acls:
      - principal: "User:${KAFKA_USERNAME}"
        resources:
          - type: "topic"
            pattern: "input-*"
            operations: ["READ"]
          - type: "topic"
            pattern: "output-*"
            operations: ["WRITE"]
``` 