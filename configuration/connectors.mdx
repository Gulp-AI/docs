---
title: "Sources and Sinks"
description: "Configure data sources and sinks for your Gulp jobs"
---

# Sources and Sinks

Gulp supports a variety of cloud-native sources and sinks, with built-in optimizations and best practices for each service.

## AWS Sources

### Amazon S3

```yaml
source:
  type: "s3"
  config:
    bucket: "my-data-bucket"
    path: "input/data/*.parquet"
    format: "parquet"  # parquet, json, csv, avro
    region: "us-west-2"
    maxConcurrentRequests: 10
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
    checkpointing:
      enabled: true
      interval: "1m"
```

### Amazon Kinesis

```yaml
source:
  type: "kinesis"
  config:
    stream: "my-data-stream"
    region: "us-west-2"
    initialPosition: "LATEST"  # LATEST, TRIM_HORIZON, AT_TIMESTAMP
    enhancedFanOut: true
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
    watermark:
      timestampField: "event_time"
      maxOutOfOrderness: "5s"
```

### Amazon MSK (Managed Streaming for Kafka)

```yaml
source:
  type: "msk"
  config:
    bootstrapServers: "${MSK_BOOTSTRAP_SERVERS}"
    topics: ["my-topic"]
    groupId: "my-consumer-group"
    securityProtocol: "SASL_SSL"
    saslMechanism: "AWS_MSK_IAM"
    isolation: "read_committed"
    monitoring:
      enabled: true
      metrics: ["lag", "throughput", "errors"]
    watermark:
      timestampField: "event_time"
      maxOutOfOrderness: "5s"
```

## AWS Sinks

### Amazon S3

```yaml
sink:
  type: "s3"
  config:
    bucket: "my-output-bucket"
    path: "output/data"
    format: "parquet"
    partitioning:
      - field: "year"
        extractFromTimestamp: "event_time"
      - field: "month"
        extractFromTimestamp: "event_time"
    compression: "snappy"
    maxFileSize: "128mb"
    inactivityInterval: "5m"
```

### Amazon Kinesis

```yaml
sink:
  type: "kinesis"
  config:
    stream: "my-output-stream"
    region: "us-west-2"
    partitionKey: "user_id"
    aggregation: true
    failOnErrors: true
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
```

### Amazon MSK

```yaml
sink:
  type: "msk"
  config:
    bootstrapServers: "${MSK_BOOTSTRAP_SERVERS}"
    topic: "my-output-topic"
    securityProtocol: "SASL_SSL"
    saslMechanism: "AWS_MSK_IAM"
    delivery: "exactly_once"
    transaction:
      timeout: "15m"
      maxAttempts: 3
```

### Amazon Redshift

```yaml
sink:
  type: "redshift"
  config:
    cluster: "my-redshift-cluster"
    database: "my_database"
    table: "my_table"
    region: "us-west-2"
    loadMethod: "copy"  # copy, insert
    staging:
      bucket: "my-staging-bucket"
      path: "redshift-staging"
    batchSize: "1000"
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
```

## GCP Sources

### Google Cloud Storage (GCS)

```yaml
source:
  type: "gcs"
  config:
    bucket: "my-data-bucket"
    path: "input/data/*.parquet"
    format: "parquet"  # parquet, json, csv, avro
    maxConcurrentRequests: 10
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
    checkpointing:
      enabled: true
      interval: "1m"
```

### Google Cloud Pub/Sub

```yaml
source:
  type: "pubsub"
  config:
    subscription: "projects/my-project/subscriptions/my-subscription"
    maxOutstandingMessages: 1000
    maxOutstandingBytes: "1gb"
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
    watermark:
      timestampField: "event_time"
      maxOutOfOrderness: "5s"
```

### BigQuery

```yaml
source:
  type: "bigquery"
  config:
    project: "my-project"
    dataset: "my_dataset"
    table: "my_table"
    viewMaterializationProject: "my-project"  # For views
    viewMaterializationDataset: "temp_dataset"
    parallelism: 10
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
```

## GCP Sinks

### Google Cloud Storage (GCS)

```yaml
sink:
  type: "gcs"
  config:
    bucket: "my-output-bucket"
    path: "output/data"
    format: "parquet"
    partitioning:
      - field: "year"
        extractFromTimestamp: "event_time"
      - field: "month"
        extractFromTimestamp: "event_time"
    compression: "snappy"
    maxFileSize: "128mb"
    inactivityInterval: "5m"
```

### Google Cloud Pub/Sub

```yaml
sink:
  type: "pubsub"
  config:
    topic: "projects/my-project/topics/my-topic"
    batchSize: 100
    maxBatchSize: "1mb"
    maxBatchDuration: "500ms"
    orderingKey: "user_id"  # For ordered delivery
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
```

### BigQuery

```yaml
sink:
  type: "bigquery"
  config:
    project: "my-project"
    dataset: "my_dataset"
    table: "my_table"
    createDisposition: "CREATE_IF_NEEDED"
    writeDisposition: "WRITE_APPEND"
    partitioning:
      type: "time"
      field: "event_time"
      expirationMs: 2592000000  # 30 days
    clustering:
      fields: ["user_id", "event_type"]
    monitoring:
      enabled: true
      metrics: ["latency", "throughput", "errors"]
```

## Common Features

All sources and sinks support these common configurations:

### Error Handling

```yaml
errorHandling:
  retries:
    maxAttempts: 3
    backoffPeriod: "1s"
    maxBackoffPeriod: "1m"
    multiplier: 2.0
  deadLetter:
    enabled: true
    destination: "s3://my-bucket/dead-letter"  # or gs:// for GCP
```

### Monitoring

```yaml
monitoring:
  metrics:
    - name: "throughput"
      interval: "1m"
    - name: "latency"
      interval: "1m"
    - name: "errors"
      interval: "1m"
  alerts:
    - name: "HighLatency"
      threshold: "5s"
      duration: "5m"
    - name: "HighErrorRate"
      threshold: 0.01
      duration: "5m"
```

### Schema Evolution

```yaml
schema:
  evolution:
    mode: "forward"  # forward, backward, full
    compatibility: "strict"  # strict, relaxed
  validation:
    enabled: true
    mode: "warn"  # warn, fail
```

<Tip>
**Performance Tip**: For optimal performance, adjust batch sizes and parallelism based on your data volume and latency requirements.
</Tip>

<Warning>
Remember to configure appropriate IAM roles and permissions for accessing these services. Refer to the cloud-specific documentation for security best practices. 